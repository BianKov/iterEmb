# How to install


# Setting up the environment
```bash
conda create -n iterEmb python=3.9
conda activate iterEmb
conda install -c conda-forge mamba -y
mamba install -c conda-forge -c bioconda -c conda-forge snakemake graph-tool scikit-learn numpy==1.23.5 numba scipy pandas networkx seaborn matplotlib gensim ipykernel tqdm black -y

pip install python-louvain
pip install infomap

pip install -e .
cd libs && pip install -e .
```

# Usage

```python
embs = iterativeEmbedding(adj, emb_func, edge_weighting_func, n_iters = 20)
```


# iterEmb

Two executable Python files are attached:
- embedWithSpectralMethods.py shows through the example of Laplacian Eigenmaps how I use spectral embedding methods. Besides Laplacian Eigenmaps, the implemented embeddings are the Euclidean Isomap (which I use with a new, exponentializing step), and its hyperbolic analogue given by TREXPIC. Isomap and TREXPIC are slower (calculate all the shortest path lengths in the network) and more memory intensive (store the matrix of shortest path lengths) than Laplacian Eigenmaps.
- embedWithRandomWalkMethods.py shows how I iterate node2vec. An important difference compared to the applied spectral methods is that node2vec needs proximity-like link weights as input (where higher values indicate stronger connections and thus, smaller expected distance in the embedding space), while the other methods start from distance-like link weights (higher values correspond to higher expected distances in the embedding space). Similarly, the returned NetworkX graph contains proximity-like link weights in the case of node2vec and distance-like link weights in the case of the spectral methods.

I included in the examples a simple weight thresholding technique for community detection, as well as Louvain (that needs proximity-like weights, and therefore, its application is different in the case of node2vec and the spectral methods) and k-means clustering (that builds solely on the node coordinates and does not use the weighted graph, so it can be used in the same way for all the implemented Euclidean embedding methods).

The codes save the modularity of the detected community structures and also similarity measures (adjusted mutual information, adjusted rand index and element-centric similarity) calculated between the detected and the planted partitions (the example graph was generated by the planted partition model).

Please note that some functions that I use are not included in NetworkX 3.0 and 3.1. I tried to indicate in comments in embedding.py what could be done in newer versions of NetworkX where I noticed that problems will occur, but I mostly use older versions of NetworkX like 2.8.
