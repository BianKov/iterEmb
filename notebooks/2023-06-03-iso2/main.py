# -*- coding: utf-8 -*-
# @Author: Sadamori Kojaku
# @Date:   2023-06-03 14:33:10
# @Last Modified by:   Sadamori Kojaku
# @Last Modified time: 2023-06-03 21:46:17
# A function for creating a weighted version of a graph based on its d-dimensional Euclidean embedding generated by the Isomap method.
# G is the (weighted) NetworkX Graph to be embedded (If link weights are inputted, these must mean distances, i.e. larger value:=less similarity or weaker connection!)
# d is the number of dimensions of the space to which the network will be embedded
# The function returns the weighted NetworkX Graph G_embWeighted and the dictionary Coord that assigns to each node name a NumPy array of d elements containing the Cartesian coordinates of the given network node in the d-dimensional Euclidean space.
# Example for function call:
#   [G_w,positionDict]=embedding.ISO(G,d)
# %%
import numpy as np
import networkx as nx
from scipy import sparse

def ISO(G, d):
    N = len(G)  # the number of nodes in graph G
    if N < d:
        print(
            "\n\nERROR: The number d of embedding dimensions in the function embedding.ISO can not be larger than the number of nodes, i.e. "
            + str(N)
            + ".\n\n"
        )

    # create the matrix to be reduced
    shortestPathLengthsDict = dict(nx.shortest_path_length(G, weight="weight"))
    # shortestPathLengthDict[source][target]=length of the shortest path from the source node to the target node

    # create the matrix of expected Euclidean distances
    listOfNodes = list(G.nodes())
    D = np.array(
        [[shortestPathLengthsDict[s][t] for t in listOfNodes] for s in listOfNodes]
    )  # D[i][j] is the expected Euclidean distance given by the length of the shortest path from the ith node to the jth node, where the nodes are ordered according to listOfNodes

    # centering, i.e. the creation of the matrix of expected inner products
    H = np.identity(N) - np.ones((N, N)) / N  # centering matrix
    IP = (
        -np.matmul(np.matmul(H, np.multiply(D, D)), H) / 2
    )  # multiply=element-wise product

    # dimension reduction
    if d == N:
        U, S, VT = np.linalg.svd(
            IP
        )  # find all the N number of singular values and the corresponding singular vectors (with decreasing order of the singular values in S)
        # note that for real matrices the conjugate transpose is just the transpose, i.e. V^H=V^T
    else:  # d<N: only the first d largest singular values (and the corresponding singular vectors) are retained
        U, S, VT = sparse.linalg.svds(
            IP, d, which="LM", solver="arpack"
        )  # the singular values are ordered from the smallest to the largest in S (increasing order)
        # reverse the order of the singular values to obtain a decreasing order, and reverse the order of singular vectors accordingly:
        S = S[::-1]
        U = U[:, ::-1]
        VT = VT[::-1]
    numOfPositiveSingularValues = np.sum(S > 0)
    if numOfPositiveSingularValues < d:
        print(
            "\n\nERROR: The number d of embedding dimensions in the function embedding.ISO can not be larger than the number of positive singular values of the inner product matrix, i.e. "
            + str(numOfPositiveSingularValues)
            + ".\n\n"
        )
    Ssqrt = np.sqrt(S)

    # create the dictionary of node positions: key=node name, value=NumPy array of d elements containing the Cartesian coordinates of the given node in the Euclidean space
    Coord = (
        {}
    )  # initialize a dictionary that assigns to the node names NumPy arrays of d elements containing the Cartesian coordinates of the network nodes in the d-dimensional Euclidean space
    nodeIndex = 0
    for nodeName in listOfNodes:
        # calculate the position of the given node
        Uarray = U[nodeIndex, :]
        Coord[nodeName] = np.multiply(
            Uarray, Ssqrt
        )  # the jth element is the jth Cartesian coordinate of the node named nodeName in the reduced space
        # we could also use: Varray = VT[:,nodeIndex] and then Coord[nodeName] = np.multiply(Varray,Ssqrt)
        nodeIndex = nodeIndex + 1

    # create the graph with embedding-based link weights
    G_embWeighted = nx.Graph()
    G_embWeighted.add_nodes_from(G.nodes)  # keep the node order of the original graph
    for i, j in G.edges():  # (i,j)=a tuple, which denotes the edge between node u and v
        # assign a weight to the i-j edge:
        w = 1.0 - (
            np.inner(Coord[i], Coord[j])
            / (np.linalg.norm(Coord[i]) * np.linalg.norm(Coord[j]))
        )  # weight=cosine distance=1-cos(dTheta)
        if w < 0:  # a numerical error has occurred
            w = 0.0
        if w > 2:  # a numerical error has occurred
            w = 2.0
        G_embWeighted.add_edge(i, j, weight=w)

    return [G_embWeighted, Coord]


def ISOv2(G, d):
    A = to_scipy_matrix(G, return_node_labels=False)
    N = A.shape[0]  # the number of nodes in graph G
    if N < d:
        raise ValueError(
            "\n\nERROR: The number d of embedding dimensions in the function embedding.ISO can not be larger than the number of nodes, i.e. "
            + str(N)
            + ".\n\n"
        )

    # create the matrix to be reduced
    D = sparse.csgraph.shortest_path(A, directed=False)

    # centering, i.e. the creation of the matrix of expected inner products
    Dsq = D**2
    # H = sparse.eye(N) - np.ones((N, N)) / N  # centering matrix
    # IP = -(H @ Dsq) @ H / 2  # multiply=element-wise product
    H_Dsq = Dsq - np.ones((N, 1)) @ np.mean(Dsq, axis=0)
    IP = (
        -(H_Dsq - np.ones((N, 1)) @ np.mean(H_Dsq, axis=0)) / 2
    )  # multiply=element-wise product

    # dimension reduction
    if d == N:
        U, S, VT = np.linalg.svd(
            IP
        )  # find all the N number of singular values and the corresponding singular vectors (with decreasing order of the singular values in S)
        # note that for real matrices the conjugate transpose is just the transpose, i.e. V^H=V^T
    else:  # d<N: only the first d largest singular values (and the corresponding singular vectors) are retained
        U, S, VT = sparse.linalg.svds(
            IP, d, which="LM", solver="arpack"
        )  # the singular values are ordered from the smallest to the largest in S (increasing order)
        # reverse the order of the singular values to obtain a decreasing order, and reverse the order of singular vectors accordingly:
        S = S[::-1]
        U = U[:, ::-1]
        VT = VT[::-1]
    numOfPositiveSingularValues = np.sum(S > 0)
    if numOfPositiveSingularValues < d:
        raise ValueError(
            "\n\nERROR: The number d of embedding dimensions in the function embedding.expISO can not be larger than the number of positive singular values of the inner product matrix, i.e. "
            + str(numOfPositiveSingularValues)
            + ".\n\n"
        )
    Ssqrt = np.sqrt(S)

    # create the dictionary of node positions: key=node name, value=NumPy array of d elements containing the Cartesian coordinates of the given node in the Euclidean space
    Coord = np.einsum("ij,j->ij", U, Ssqrt)

    src, trg, weights = sparse.find(A)
    nCoord = np.einsum(
        "ij,i->ij", Coord, 1 / np.linalg.norm(Coord, axis=1)
    )  # row-normalized array
    new_weights = 1.0 - np.array(
        np.sum(nCoord[src, :] * nCoord[trg, :], axis=1)
    ).reshape(-1)

    new_weights = np.clip(new_weights, 0.0, 2.0)
    Anew = sparse.csr_matrix((new_weights, (src, trg)), shape=A.shape)

    # I remove the conversion of the results to networkx.Graph since it is inefficient.
    return Anew, Coord


# utils
def to_scipy_matrix(net, return_node_labels=False):
    """
    Converts a networkx graph, a SciPy sparse matrix or a numpy ndarray to a SciPy sparse matrix in CSR format.

    Parameters
    ----------
    net : nx.Graph or scipy.sparse.spmatrix or numpy.ndarray
        The input graph or matrix to convert.
    return_node_labels : bool, optional (default=False)
        Whether to return node labels or not. If True and the input is a networkx graph,
        then a list of node labels will be returned along with the sparse matrix.

    Returns
    -------
    scipy.sparse.csr_matrix
        The converted sparse matrix in CSR format.
    list, optional
        If `return_node_labels` is True and the input is a networkx graph,
        a list of node labels corresponding to the rows/columns of the sparse matrix.

    Raises
    ------
    ValueError
        If the input is not of type nx.Graph, scipy.sparse.spmatrix or numpy.ndarray.
    """
    _node_labels = None
    if isinstance(net, nx.Graph):
        _net = nx.to_scipy_sparse_array(
            net, weight="weight", format="csr"
        )  # adjacency matrix as a SciPy sparse matrix

        if return_node_labels:
            _node_labels = list(net.nodes())
    elif sparse.issparse(net):
        _net = net
        if return_node_labels:
            _node_labels = np.arange(net.shape[0], dtype=np.int64)
    elif isinstance(net, np.ndarray):
        _net = sparse.csr_matrix(net)
        if return_node_labels:
            _node_labels = np.arange(net.shape[0], dtype=np.int64)
    else:
        ValueError("Unexpected data type {} for the adjacency matrix".format(type(net)))

    if return_node_labels:
        return _net, _node_labels
    else:
        return _net

import graph_tool.all as gt
g = gt.collection.ns["polblogs"]
# %%
A = gt.adjacency(g).T
G = nx.from_scipy_sparse_array(A + A.T)

# %%
%%time
retvals = ISOv2(G, d=12)
# %%
%%time
retvals2 = ISO(G, d=12)
# %%
W = nx.adjacency_matrix(retvals2[0])
dB = retvals[0] - W
np.max(np.abs(dB.data))

